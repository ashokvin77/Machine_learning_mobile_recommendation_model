{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This project applies machine learning models to analyze the behavior of mobile subscribers. The company Megaline found that many subscribers use legacy plans. They want to recommend one of two new plans to subscribers: Smart or Ultra, based on the behavior of subscribers who have already started using either Smart or Ultra. The goal is to develop a model with an accuracy greater than or equal to 0.75.\n",
    "\n",
    "**Data Description**\n",
    "\n",
    "Every observation in the dataset contains monthly behavior information about one user. The information given is as follows:\n",
    "\n",
    "- `calls` — number of calls,\n",
    "- `minutes` — total call duration in minutes,\n",
    "- `messages` — number of text messages,\n",
    "- `mb_used` — Internet traffic used in MB,\n",
    "- `is_ultra` — plan for the current month (Ultra - 1, Smart - 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open and look through the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "try:\n",
    "    users_df = pd.read_csv('users_behavior.csv')\n",
    "except FileNotFoundError:\n",
    "    users_df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>74.0</td>\n",
       "      <td>456.81</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20700.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>118.0</td>\n",
       "      <td>799.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12828.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>35.0</td>\n",
       "      <td>236.72</td>\n",
       "      <td>72.0</td>\n",
       "      <td>13380.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>106.0</td>\n",
       "      <td>781.37</td>\n",
       "      <td>26.0</td>\n",
       "      <td>37962.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>101.0</td>\n",
       "      <td>694.20</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9351.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "2014   74.0   456.81      27.0  20700.46         0\n",
       "845   118.0   799.40       0.0  12828.73         1\n",
       "962    35.0   236.72      72.0  13380.67         0\n",
       "1559  106.0   781.37      26.0  37962.31         1\n",
       "1116  101.0   694.20      41.0   9351.78         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine few rows\n",
    "\n",
    "users_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Examine dataset\n",
    "\n",
    "users_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it is appropriate to change the columns `calls` and `messages` to int64 because decimals do not make sense here. I would change the column `is_ultra` to category dtype if I were doing general data analysis. Since I am working with machine learning, I will keep that column as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing float64 to int64\n",
    "users_df['calls'] = users_df['calls'].astype('int64')\n",
    "users_df['messages'] = users_df['messages'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "\n",
    "users_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates\n",
    "\n",
    "users_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and target\n",
    "\n",
    "features = users_df.drop(['is_ultra'], axis=1)\n",
    "target = users_df['is_ultra'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the source data into a training set, a validation set, and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_ultra\n",
      "0    69.35 %\n",
      "1    30.65 %\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data. \n",
    "# Before splitting the data, lets check the proportion of the target.\n",
    "\n",
    "proportion = users_df['is_ultra'].value_counts(normalize=True)*100\n",
    "print(proportion.apply(lambda x: f\"{x:.2f} %\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that that the output is skewed. So, we need to maintain this skewness while splitting the data to \n",
    "get the flavor of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Split: keep 20 % of data from the orinigal data as test data\n",
    "# This dataset will will be used in final evaluation\n",
    "# The remaining 80% (features_tr_val, target_tr_val) will be used for training and validation.\n",
    "# In order to ensure the proportion of `0`s and `1`s in the test set, I use (`stratify=target`).\n",
    "\n",
    "features_tr_val, features_test, target_tr_val, target_test = train_test_split(\n",
    "    features, target, test_size = 0.2, random_state = 123, stratify = target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: From the remaining 80 % of the data, allocate 60 % for training and 20 % for validation\n",
    "# `features_tr` and `target_tr` will be used for model training.\n",
    "#  `features_val` and `target_val` will be used for hyperparameter tuning (validation).\n",
    "\n",
    "features_tr, features_val, target_tr, target_val = train_test_split(\n",
    "    features_tr_val, target_tr_val, test_size = 0.25, random_state = 123, stratify = target_tr_val)\n",
    "\n",
    "# test_size is 20 % of 80 i.e, 25 % or 0.25.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate the quality of different models by changing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Decision Tree Accuracy: 72.47 %\n"
     ]
    }
   ],
   "source": [
    "# Lets work on Decision tree classifier\n",
    "\n",
    "#First start with default mode\n",
    "\n",
    "default_model_tree = DecisionTreeClassifier(random_state = 123)\n",
    "default_model_tree.fit(features_tr, target_tr)\n",
    "predictions_default_tree = default_model_tree.predict(features_val)\n",
    "\n",
    "# Print accuracy for the default Decision Tree model\n",
    "print(\"Default Decision Tree Accuracy:\", round(accuracy_score(target_val, predictions_default_tree)*100, 2), '%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 75.58 %\n",
      "max_depth = 2 : 77.29 %\n",
      "max_depth = 3 : 78.54 %\n",
      "max_depth = 4 : 78.54 %\n",
      "max_depth = 5 : 78.38 %\n",
      "max_depth = 6 : 77.76 %\n",
      "max_depth = 7 : 78.85 %\n",
      "max_depth = 8 : 78.54 %\n",
      "max_depth = 9 : 79.32 %\n",
      "max_depth = 10 : 78.07 %\n",
      "max_depth = 11 : 77.14 %\n",
      "max_depth = 12 : 77.29 %\n",
      "max_depth = 13 : 75.27 %\n",
      "max_depth = 14 : 75.12 %\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning: Decision Tree with different max_depth values\n",
    "for depth in range(1, 15):  # Testing max_depth from 1 to 14\n",
    "    tuned_model_tree = DecisionTreeClassifier(random_state=123, max_depth = depth)\n",
    "    tuned_model_tree.fit(features_tr, target_tr)\n",
    "    predictions_tuned_tree = tuned_model_tree.predict(features_val)\n",
    "    print(\"max_depth =\", depth, \": \", end='')\n",
    "    print(round(accuracy_score(target_val, predictions_tuned_tree)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that the optimal max_depth for the Decision Tree model was found to be 9. With that depth, the accuracy was around 79.32%. If we increase the depth, the accuracy does not increase and might suggest overfitting the model. On the other hand, if we decrease the depth, it might suggest underfitting the model. The default accuracy was around 72.47%, which suggests that it is an underfitted model. We got these values based on a random_state of 123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Random Forest Accuracy: 79.63 %\n"
     ]
    }
   ],
   "source": [
    "# Lets focus on Random forest\n",
    "\n",
    "# Default Random Forest Classifier \n",
    "default_model_rf = RandomForestClassifier(random_state = 123)\n",
    "\n",
    "# Train on training data\n",
    "default_model_rf.fit(features_tr, target_tr)\n",
    "\n",
    "# Predict on validation data\n",
    "predictions_rf_default = default_model_rf.predict(features_val)\n",
    "\n",
    "# Print accuracy for the default model\n",
    "print(\"Default Random Forest Accuracy:\", round(accuracy_score(target_val, predictions_rf_default)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best Random Forest model on the validation set (n_estimators = 42): 80.4 %\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning: Random Forest with different n_estimators (number of trees)\n",
    "best_score_rf = 0\n",
    "best_estimators_rf = 0\n",
    "\n",
    "for est in range(1, 100):  # Test n_estimators from 1 to 99\n",
    "    model_rf = RandomForestClassifier(random_state = 123, n_estimators = est)\n",
    "    model_rf.fit(features_tr, target_tr)  # Train on training data\n",
    "    score_rf = model_rf.score(features_val, target_val)  # Evaluate on validation set\n",
    "    if score_rf > best_score_rf:\n",
    "        best_score_rf = score_rf  # Update best score\n",
    "        best_estimators_rf = est  # Save the number of estimators for the best score\n",
    "\n",
    "# Output the best model's accuracy and n_estimators\n",
    "print(f\"Accuracy of the best Random Forest model on the validation set (n_estimators = {best_estimators_rf}): {round(best_score_rf * 100, 2)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that the optimal n_estimators is 42. It gives accuracy of about 80.4 %. The default parameters give accuracy of 79.63 %. If we increase n_estimators greater tha 42, it might overfit the data. On the otherhand, if n_estimators is less than 42, it might suggest underfitting of the data. The answer was based on random_state of 123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set: 74.48 %\n",
      "Accuracy of the logistic regression model on the validation set: 75.0 %\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "\n",
    "# Initialize Logistic Regression model with solver='liblinear'\n",
    "model = LogisticRegression(random_state=123, solver='liblinear')\n",
    "\n",
    "# Train the model using the training set\n",
    "model.fit(features_tr, target_tr)\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "score_train = model.score(features_tr, target_tr)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "score_valid = model.score(features_val, target_val)\n",
    "\n",
    "# Print the accuracy of the model on both the training and validation sets\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the training set:\",\n",
    "    round(score_train * 100 ,2), '%'\n",
    ")\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the validation set:\",\n",
    "    round(score_valid, 2) * 100, '%'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression accuracy was found to be lower than that of the Random Forest model but higher than the default Decision Tree. Although logistic regression is faster, it is far less accurate than the Random Forest model. With n_estimators = 42, the accuracy for Random Forest was 80.4%, which is the highest when considering random_state = 123."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the quality of the model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Accuracy on the test set (n_estimators=42): 79.94 %\n"
     ]
    }
   ],
   "source": [
    "# Best Random Forest Classifier with n_estimators=42 and random_state=123\n",
    "best_model_rf = RandomForestClassifier(random_state=123, n_estimators=42)\n",
    "\n",
    "# Train on training data\n",
    "best_model_rf.fit(features_tr, target_tr)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions_rf_test = best_model_rf.predict(features_test)\n",
    "\n",
    "# Calculate accuracy of the model on the test set\n",
    "model_rf_accuracy = accuracy_score(target_test, predictions_rf_test)\n",
    "\n",
    "# Print accuracy for the best Random Forest model on the test set\n",
    "print(\"Best Random Forest Accuracy on the test set (n_estimators=42):\", round(model_rf_accuracy * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on the test data is 79.94%, which is slightly lower than the accuracy on the validation set (80.40%). Still, the model performs well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sanity check the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the target variable is_ultra has two values: 0 for smart plan and 1 for ultra plan. We found that 69.35% of target values belong to the smart plan. This means if we were to guess the plan and choose smart (value 0), we would likely be correct 69.35% of the time. However, our best model predictions on test data achieve 78.38%. Therefore, we can say that our model performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "In this project, I successfully applied machine learning models to analyze the behaviors of Megaline mobile subscribers. The model was able to recommend plans to new users in an effective way. I performed exploratory data analysis to confirm the data is clean. Then I split data into training (60%), validation (20%) and test (20%). Since the original data was skewed, I maintained the skewness in split data.\n",
    "\n",
    "I analyzed different models such as Decision Tree, Random Forest and Logistic Regression with tuning different hyperparameters. The Random Forest model with 42 estimators and random state of 123 has the highest accuracy of 80.4% on the validation dataset. But we must keep in mind that I might have got slightly different answers if I had used different random states. I also did a sanity check which confirmed that the model is trustworthy at predicting. Finally, the best Random Forest model achieved 79.94% accuracy on the test dataset, which is above the threshold of 0.75 (75%). Therefore, the model is effective in recommending either the Smart or Ultra plans to new customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
